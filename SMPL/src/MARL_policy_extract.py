"""
å°†è®­ç»ƒå¥½çš„ç­–ç•¥éƒ¨ç½²åˆ°å®æœº
ä» best_policy æå–æ‰€éœ€æ–‡ä»¶å¹¶åˆ›å»ºä¸€ä¸ªè½»é‡çº§çš„éƒ¨ç½²åŒ…
"""

import os
import shutil
import json
from pathlib import Path
import pickle

def extract_policies_for_deployment(
    source_checkpoint: str = "/home/chenshuo/PycharmProjects/move_sim/best_policy",
    deploy_dir: str = "./deployed_policy"
) -> None:
    """
    ä»å®Œæ•´çš„ checkpoint ä¸­æå–éƒ¨ç½²æ‰€éœ€çš„æœ€å°æ–‡ä»¶é›†
    
    Args:
        source_checkpoint: è®­ç»ƒå¥½çš„ best_policy è·¯å¾„
        deploy_dir: éƒ¨ç½²æ–‡ä»¶çš„è¾“å‡ºç›®å½•
    """
    
    source_path = Path(source_checkpoint)
    deploy_path = Path(deploy_dir)
    
    print(f"[INFO] ä» {source_checkpoint} æå–éƒ¨ç½²æ–‡ä»¶...")
    print(f"[INFO] éƒ¨ç½²ç›®å½•: {deploy_dir}")
    
    # 1. åˆ›å»ºéƒ¨ç½²ç›®å½•ç»“æ„
    print("\n[STEP 1] åˆ›å»ºéƒ¨ç½²ç›®å½•ç»“æ„...")
    (deploy_path / "learner_group" / "learner" / "rl_module" / "exo_policy").mkdir(
        parents=True, exist_ok=True
    )
    (deploy_path / "learner_group" / "learner" / "rl_module" / "human_policy").mkdir(
        parents=True, exist_ok=True
    )
    
    # 2. å¤åˆ¶æ ¸å¿ƒæ–‡ä»¶ï¼šexo_policy æƒé‡
    print("\n[STEP 2] å¤åˆ¶ exo_policy æ–‡ä»¶...")
    exo_source = (
        source_path / "learner_group" / "learner" / "rl_module" / "exo_policy"
    )
    exo_deploy = deploy_path / "learner_group" / "learner" / "rl_module" / "exo_policy"
    
    required_exo_files = [
        "module_state.pkl",
        "class_and_ctor_args.pkl",
        "metadata.json"
    ]
    
    for file in required_exo_files:
        src_file = exo_source / file
        if src_file.exists():
            shutil.copy2(src_file, exo_deploy / file)
            print(f"  âœ“ å¤åˆ¶: {file}")
        else:
            print(f"  âš  æ–‡ä»¶ä¸å­˜åœ¨: {file}")
    
    # 3. å¤åˆ¶æ ¸å¿ƒæ–‡ä»¶ï¼šhuman_policy æƒé‡
    print("\n[STEP 3] å¤åˆ¶ human_policy æ–‡ä»¶...")
    human_source = (
        source_path / "learner_group" / "learner" / "rl_module" / "human_policy"
    )
    human_deploy = deploy_path / "learner_group" / "learner" / "rl_module" / "human_policy"
    
    required_human_files = [
        "module_state.pkl",
        "class_and_ctor_args.pkl",
        "metadata.json"
    ]
    
    for file in required_human_files:
        src_file = human_source / file
        if src_file.exists():
            shutil.copy2(src_file, human_deploy / file)
            print(f"  âœ“ å¤åˆ¶: {file}")
        else:
            print(f"  âš  æ–‡ä»¶ä¸å­˜åœ¨: {file}")
    
    # 4. å¤åˆ¶å…ƒæ•°æ®æ–‡ä»¶
    print("\n[STEP 4] å¤åˆ¶å…ƒæ•°æ®æ–‡ä»¶...")
    metadata_files = [
        ("rllib_checkpoint.json", source_path / "rllib_checkpoint.json"),
        ("learner_group/metadata.json", source_path / "learner_group" / "metadata.json"),
        ("learner_group/learner/metadata.json", source_path / "learner_group" / "learner" / "metadata.json"),
        ("learner_group/learner/rl_module/metadata.json", source_path / "learner_group" / "learner" / "rl_module" / "metadata.json"),
    ]
    
    for rel_path, src_file in metadata_files:
        deploy_file = deploy_path / rel_path
        deploy_file.parent.mkdir(parents=True, exist_ok=True)
        if src_file.exists():
            shutil.copy2(src_file, deploy_file)
            print(f"  âœ“ å¤åˆ¶: {rel_path}")
    
    # 5. åˆ›å»ºéƒ¨ç½²é…ç½®æ–‡ä»¶
    print("\n[STEP 5] åˆ›å»ºéƒ¨ç½²é…ç½®æ–‡ä»¶...")
    deploy_config = {
        "deployment_info": {
            "source": str(source_checkpoint),
            "created_at": str(Path(source_checkpoint).stat().st_mtime),
            "policies": ["human_policy", "exo_policy"],
            "deployment_type": "inference_only"
        },
        "required_files": {
            "exo_policy": [
                "learner_group/learner/rl_module/exo_policy/module_state.pkl",
                "learner_group/learner/rl_module/exo_policy/class_and_ctor_args.pkl"
            ],
            "human_policy": [
                "learner_group/learner/rl_module/human_policy/module_state.pkl",
                "learner_group/learner/rl_module/human_policy/class_and_ctor_args.pkl"
            ]
        },
        "optional_files": {
            "metadata": [
                "rllib_checkpoint.json",
                "learner_group/metadata.json"
            ]
        }
    }
    
    config_file = deploy_path / "deployment_config.json"
    with open(config_file, "w") as f:
        json.dump(deploy_config, f, indent=2)
    print(f"  âœ“ åˆ›å»º: deployment_config.json")
    
    # 6. è¾“å‡ºéƒ¨ç½²ä¿¡æ¯
    print("\n" + "="*70)
    print("[SUCCESS] éƒ¨ç½²æ–‡ä»¶å‡†å¤‡å®Œæˆï¼")
    print("="*70)
    
    # è®¡ç®—æ–‡ä»¶å¤§å°
    total_size = sum(
        f.stat().st_size 
        for f in deploy_path.rglob("*") 
        if f.is_file()
    )
    
    print(f"\néƒ¨ç½²ä½ç½®: {deploy_path}")
    print(f"æ€»æ–‡ä»¶å¤§å°: {total_size / 1024 / 1024:.2f} MB")
    print(f"\néƒ¨ç½²æ–‡ä»¶ç»“æ„:")
    
    for root, dirs, files in os.walk(deploy_path):
        level = root.replace(str(deploy_path), "").count(os.sep)
        indent = " " * 2 * level
        print(f"{indent}ğŸ“ {os.path.basename(root)}/")
        subindent = " " * 2 * (level + 1)
        for file in files:
            file_path = Path(root) / file
            file_size = file_path.stat().st_size / 1024
            print(f"{subindent}ğŸ“„ {file} ({file_size:.2f} KB)")
    
    print("\n" + "="*70)


def verify_deployment(deploy_dir: str = "./deployed_policy") -> bool:
    """
    éªŒè¯éƒ¨ç½²æ–‡ä»¶çš„å®Œæ•´æ€§
    
    Args:
        deploy_dir: éƒ¨ç½²ç›®å½•
        
    Returns:
        True å¦‚æœéƒ¨ç½²æ–‡ä»¶å®Œæ•´ï¼ŒFalse å¦åˆ™
    """
    
    print(f"\n[INFO] éªŒè¯éƒ¨ç½²æ–‡ä»¶å®Œæ•´æ€§...")
    deploy_path = Path(deploy_dir)
    
    required_files = [
        "rllib_checkpoint.json",
        "learner_group/learner/rl_module/exo_policy/module_state.pkl",
        "learner_group/learner/rl_module/exo_policy/class_and_ctor_args.pkl",
        "learner_group/learner/rl_module/human_policy/module_state.pkl",
        "learner_group/learner/rl_module/human_policy/class_and_ctor_args.pkl",
    ]
    
    all_ok = True
    for file_path in required_files:
        full_path = deploy_path / file_path
        if full_path.exists():
            size_kb = full_path.stat().st_size / 1024
            print(f"  âœ“ {file_path} ({size_kb:.2f} KB)")
        else:
            print(f"  âœ— {file_path} (ç¼ºå¤±)")
            all_ok = False
    
    if all_ok:
        print("\n[SUCCESS] âœ… æ‰€æœ‰å¿…è¦æ–‡ä»¶éƒ½å·²å‡†å¤‡å¥½ï¼")
    else:
        print("\n[ERROR] âŒ éƒ¨åˆ†æ–‡ä»¶ç¼ºå¤±ï¼Œè¯·æ£€æŸ¥ï¼")
    
    return all_ok


if __name__ == "__main__":
    # æå–éƒ¨ç½²æ–‡ä»¶
    extract_policies_for_deployment(
        source_checkpoint="/home/chenshuo/PycharmProjects/move_sim/best_policy",
        deploy_dir="/home/chenshuo/PycharmProjects/move_sim/deployed_policy"
    )
    
    # éªŒè¯éƒ¨ç½²
    verify_deployment("./deployed_policy")