# å¿«é€Ÿå‚è€ƒï¼šMARL è®­ç»ƒæ•°æ®è®°å½•

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. è¿è¡Œè®­ç»ƒ
```bash
cd /home/chenshuo/PycharmProjects/move_sim
python -m SMPL.src.MARL_training
```

### 2. æŸ¥çœ‹è®­ç»ƒæ•°æ®
è®­ç»ƒå®Œæˆåï¼Œæ£€æŸ¥è¿™äº›æ–‡ä»¶ï¼š
```
final_training_logs/
â”œâ”€â”€ optimal_hyperparams.txt      # æœ€ä¼˜è¶…å‚æ•°
â””â”€â”€ training_metrics.csv         # è¯¦ç»†è®­ç»ƒæŒ‡æ ‡
```

### 3. ç”Ÿæˆåˆ†ææŠ¥å‘Š
```bash
python SMPL/src/analyze_training_logs.py
```

ç”Ÿæˆçš„æ–‡ä»¶ï¼š
```
final_training_logs/
â”œâ”€â”€ 01_rewards.png               # å¥–åŠ±æ›²çº¿
â”œâ”€â”€ 02_losses.png                # æŸå¤±æ›²çº¿
â”œâ”€â”€ 03_summary.png               # æ€§èƒ½æ€»ç»“
â””â”€â”€ training_report.txt          # è¯¦ç»†ç»Ÿè®¡æŠ¥å‘Š
```

## ğŸ“Š å…³é”®æŒ‡æ ‡è¯´æ˜

### å¥–åŠ± (Rewards)
- **exo_reward**: å¤–éª¨éª¼ç­–ç•¥åœ¨æ¯ä¸ª iteration çš„å¹³å‡å›åˆå›æŠ¥
- **human_reward**: äººç±»ç­–ç•¥åœ¨æ¯ä¸ª iteration çš„å¹³å‡å›åˆå›æŠ¥
- æ›´é«˜æ›´å¥½ï¼Œé€šå¸¸æ˜¯è´Ÿæ•°ï¼ˆæƒ©ç½šä¸ºä¸»ï¼‰

### æŸå¤± (Losses)
- **policy_loss**: ç­–ç•¥ç›®æ ‡å‡½æ•°çš„æŸå¤±ï¼Œè¶Šå°è¶Šå¥½
- **vf_loss**: ä»·å€¼å‡½æ•°çš„é¢„æµ‹è¯¯å·®ï¼Œè¶Šå°è¶Šå¥½
- ç”¨äºä¼˜åŒ–ç­–ç•¥ç½‘ç»œçš„æ¢¯åº¦

### ç†µ (Entropy)  
- **entropy**: ç­–ç•¥åˆ†å¸ƒçš„ç†µï¼Œè¡¨ç¤ºç­–ç•¥çš„éšæœºæ€§
- é«˜ç†µ = åŠ¨ä½œåˆ†å¸ƒå¹³å‡ = æ›´å¤šæ¢ç´¢
- ä½ç†µ = é›†ä¸­åœ¨æŸäº›åŠ¨ä½œ = æ›´å¤šå¼€å‘
- é€šå¸¸éœ€è¦é€æ¸ä¸‹é™çš„ç†µæ¥è¾¾åˆ°æ”¶æ•›

### å…¶ä»–æŒ‡æ ‡
- **episode_return_mean**: æ‰€æœ‰æ™ºèƒ½ä½“çš„å¹³å‡å›æŠ¥
- **episode_len_mean**: å¹³å‡å›åˆé•¿åº¦ï¼ˆç¯å¢ƒæ­¥æ•°ï¼‰
- **num_episodes**: æœ¬ iteration äº§ç”Ÿçš„å›åˆæ•°

## ğŸ“ˆ å¦‚ä½•è¯»å–å’Œåˆ†ææ•°æ®

### ç”¨ Pandas è¯»å– CSV
```python
import pandas as pd

# è¯»å–è®­ç»ƒæŒ‡æ ‡
df = pd.read_csv('final_training_logs/training_metrics.csv')

# æŸ¥çœ‹å‰å‡ è¡Œ
print(df.head())

# åŸºæœ¬ç»Ÿè®¡
print(df.describe())

# ç»˜åˆ¶æŸä¸ªæŒ‡æ ‡
import matplotlib.pyplot as plt
plt.plot(df['iteration'], df['exo_reward'])
plt.xlabel('Iteration')
plt.ylabel('Exo Reward')
plt.show()
```

### å¯¹æ¯”ä¸åŒè¶…å‚æ•°ç»„åˆ
```python
# ä»ç½‘æ ¼æœç´¢ç»“æœä¸­è¯»å–æ•°æ®
import glob
import pandas as pd

# æŸ¥æ‰¾æ‰€æœ‰ç½‘æ ¼æœç´¢è¯•éªŒ
trials = glob.glob('ray_results/marl_exo_reward_grid/PPO_MARL_EXO_ENV_*/progress.csv')

# æ¯”è¾ƒæœ€ç»ˆæ€§èƒ½
for trial in trials:
    df = pd.read_csv(trial)
    final_reward = df['env_runners/module_episode_returns_mean/exo_policy'].iloc[-1]
    trial_name = trial.split('/')[-2]
    print(f"{trial_name}: {final_reward:.2f}")
```

## ğŸ” å¸¸è§é—®é¢˜

### Q: ä¸ºä»€ä¹ˆå¥–åŠ±æ˜¯è´Ÿæ•°ï¼Ÿ
**A**: è¿™å¾ˆæ­£å¸¸ã€‚ç¯å¢ƒä¸­å¤§éƒ¨åˆ†æ˜¯æƒ©ç½šé¡¹ï¼ˆä½ç½®é”™è¯¯ã€èƒ½è€—ç­‰ï¼‰ï¼Œå¥–åŠ±æ¥è¿‘ 0 çš„è´Ÿæ•°æ˜¯å¥½çš„ã€‚

### Q: å¦‚ä½•åˆ¤æ–­è®­ç»ƒæ˜¯å¦æ”¶æ•›ï¼Ÿ
**A**: 
- å¥–åŠ±æ›²çº¿å˜å¹³ç¼“
- ç­–ç•¥æŸå¤±å’Œ VF æŸå¤±é€æ¸å‡å°
- ç†µé€æ¸é™ä½
- è¿ç»­å¤šä¸ª iteration æ²¡æœ‰æ˜¾è‘—æ”¹è¿›

### Q: training_metrics.csv ä¸­æœ‰ NaN å€¼ï¼Ÿ
**A**: å¯èƒ½æ˜¯æŸäº› iteration æ²¡æœ‰äº§ç”Ÿç›¸åº”çš„æŒ‡æ ‡ã€‚æ£€æŸ¥ `num_episodes` æ˜¯å¦ä¸º 0ã€‚

### Q: å¦‚ä½•å¯¼å‡ºæ•°æ®åˆ° Excelï¼Ÿ
```python
import pandas as pd

# è¯»å– CSV
df = pd.read_csv('final_training_logs/training_metrics.csv')

# å†™å…¥ Excel
df.to_excel('final_training_logs/training_metrics.xlsx', index=False)
```

### Q: å¦‚ä½•å¯¹æ¯”å¤šæ¬¡è®­ç»ƒè¿è¡Œï¼Ÿ
```python
import pandas as pd
import os

all_data = []
for run_dir in ['run_1', 'run_2', 'run_3']:
    csv_file = f'{run_dir}/final_training_logs/training_metrics.csv'
    df = pd.read_csv(csv_file)
    df['run'] = run_dir
    all_data.append(df)

combined = pd.concat(all_data, ignore_index=True)
print(combined.groupby('run')['exo_reward'].describe())
```

## ğŸ“‹ æ–‡ä»¶æ¸…å•

| æ–‡ä»¶ | æè¿° | ä½•æ—¶ç”Ÿæˆ |
|-----|------|--------|
| `optimal_hyperparams.txt` | æœ€ä¼˜è¶…å‚æ•° | è¿è¡Œå¼€å§‹æ—¶ |
| `training_metrics.csv` | æ¯ä¸ª iteration çš„è¯¦ç»†æŒ‡æ ‡ | æ¯ä¸ª iteration ç»“æŸæ—¶ |
| `reward_terms_by_episode.csv` | æ¯ä¸ª episode çš„å¥–åŠ±åˆ†é‡ | æ¯ä¸ª episode ç»“æŸæ—¶ |
| `01_rewards.png` | å¥–åŠ±æ›²çº¿å›¾ | è¿è¡Œ `analyze_training_logs.py` |
| `02_losses.png` | æŸå¤±æ›²çº¿å›¾ | è¿è¡Œ `analyze_training_logs.py` |
| `03_summary.png` | æ€§èƒ½æ€»ç»“å›¾ | è¿è¡Œ `analyze_training_logs.py` |
| `training_report.txt` | ç»Ÿè®¡æŠ¥å‘Š | è¿è¡Œ `analyze_training_logs.py` |

## ğŸ¯ å…¸å‹å·¥ä½œæµ

1. **å‡†å¤‡é˜¶æ®µ**
   ```bash
   # ç¼–è¾‘å‚æ•°
   vim SMPL/src/MARL_training.py  # è°ƒæ•´ max_iters, save_interval ç­‰
   ```

2. **è®­ç»ƒé˜¶æ®µ**
   ```bash
   python -m SMPL.src.MARL_training
   # è¿™å°†è¿è¡Œç½‘æ ¼æœç´¢ + æœ€ä¼˜è¶…å‚æ•°è®­ç»ƒ
   # å¤§çº¦éœ€è¦ 10-30 åˆ†é’Ÿï¼ˆå–å†³äºç¡¬ä»¶ï¼‰
   ```

3. **åˆ†æé˜¶æ®µ**
   ```bash
   python SMPL/src/analyze_training_logs.py
   # ç”Ÿæˆå›¾è¡¨å’ŒæŠ¥å‘Š
   ```

4. **è¯„ä¼°é˜¶æ®µ**
   ```bash
   # æŸ¥çœ‹ç”Ÿæˆçš„å¯è§†åŒ–å’ŒæŠ¥å‘Š
   cat final_training_logs/training_report.txt
   open final_training_logs/03_summary.png  # macOS
   # æˆ–
   display final_training_logs/03_summary.png  # Linux
   ```

5. **æ¨¡å‹éƒ¨ç½²**
   ```bash
   # æœ€å¥½çš„æ¨¡å‹å·²ä¿å­˜åœ¨ best_policy/
   # æœ€è¿‘çš„æ£€æŸ¥ç‚¹åœ¨ final_policy_checkpoints/
   ```

## ğŸ”§ è‡ªå®šä¹‰æ—¥å¿—

### æ·»åŠ æ–°æŒ‡æ ‡
ç¼–è¾‘ `MARL_training.py` çš„ `_init_metrics_csv()` å’Œ `_log_training_metrics()` å‡½æ•°ï¼š

```python
# åœ¨ _init_metrics_csv() ä¸­æ·»åŠ è¡¨å¤´
writer.writerow([
    "iteration",
    "exo_reward",
    "human_reward",
    # æ·»åŠ æ–°åˆ—
    "avg_step_time",
    "gpu_memory_used",
    # ...
])

# åœ¨ _log_training_metrics() ä¸­æå–æ–°æŒ‡æ ‡
avg_step_time = metrics.get("perf", {}).get("avg_step_time")
gpu_mem = metrics.get("perf", {}).get("gpu_memory_used")

# å†™å…¥æ—¶åŒ…å«æ–°å€¼
writer.writerow([
    iteration,
    exo_reward,
    human_reward,
    avg_step_time,
    gpu_mem,
    # ...
])
```

### æ›´æ”¹æ—¥å¿—ä½ç½®
```python
# åœ¨ main() å‡½æ•°ä¸­
log_dir = "/path/to/your/logs"
```

---

**æœ€åæ›´æ–°**: 2025å¹´11æœˆ20æ—¥  
**ç›¸å…³æ–‡ä»¶**: 
- `SMPL/src/MARL_training.py` - ä¸»è®­ç»ƒè„šæœ¬
- `SMPL/src/analyze_training_logs.py` - åˆ†æè„šæœ¬
- `TRAINING_LOG_GUIDE.md` - è¯¦ç»†æŒ‡å—
