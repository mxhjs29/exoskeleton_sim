iteration,exo_reward,human_reward,episode_return_mean,episode_len_mean,policy_loss_human,policy_loss_exo,vf_loss_human,vf_loss_exo,entropy_human,entropy_exo,num_episodes
0,-100.5,-85.3,-185.8,250,0.5,0.6,0.3,0.4,2.5,2.3,12
1,-105.5,-88.3,-193.8,252,0.45,0.54,0.27,0.36000000000000004,2.4,2.1799999999999997,14
2,-110.5,-91.3,-201.8,254,0.4,0.48,0.24,0.32,2.3,2.0599999999999996,16
3,-115.5,-94.3,-209.8,256,0.35,0.42,0.21,0.28,2.2,1.94,18
4,-120.5,-97.3,-217.8,258,0.3,0.36,0.18,0.24000000000000002,2.1,1.8199999999999998,20
5,-125.5,-100.3,-225.8,260,0.25,0.3,0.15,0.2,2.0,1.6999999999999997,22
